SELECT year, month, west
  FROM tutorial.us_housing_units
  
  SELECT *
  FROM tutorial.us_housing_units
  
  SELECT year, month, month_name, south, west, midwest, northeast
  FROM tutorial.us_housing_units
  
  SELECT year, month, month_name, south, west, midwest, northeast
  FROM tutorial.us_housing_units
  WHERE year >= 1970
  
  SELECT year, month, month_name, south, west, midwest, northeast
  FROM tutorial.us_housing_units
  WHERE month_name = 'February' AND NOT year >= 1970
  
  SELECT year AS "Year", month AS "Month", month_name AS "Month Name", south AS "South Region", west AS "West Region", midwest AS "Midwest Region", northeast AS "Northeast Region"
  FROM tutorial.us_housing_units
  WHERE month_name <= 'N'
  
  SELECT year, month, west + south AS south_plus_west, west + south + midwest + northeast AS Total_Sum
  FROM tutorial.us_housing_units
  WHERE west + south >= 50
  
  SELECT *, midwest + northeast AS BigTen_Sum 
  FROM tutorial.us_housing_units
  WHERE west > (midwest + northeast)
  
  SELECT *, south + west + midwest + northeast AS Total_Sum, 100 * west / (south + west + midwest + northeast) AS west_pct,
    100 * south / (south + west + midwest + northeast) AS south_pct,
    100 * midwest / (south + west + midwest + northeast) AS midwest_pct,
    100 * northeast / (south + west + midwest + northeast) AS northeast_pct
  FROM tutorial.us_housing_units
  WHERE year >= 2000
  
SELECT *
FROM tutorial.billboard_top_100_year_end
ORDER BY year ASC, year_rank ASC

SELECT *
FROM tutorial.billboard_top_100_year_end
WHERE group_name ILIKE '%ludacris%'

SELECT *
FROM tutorial.billboard_top_100_year_end
WHERE group_name ILIKE 'dj%'

SELECT *
FROM tutorial.billboard_top_100_year_end
WHERE group_name ILIKE '%MC%'

SELECT *
FROM tutorial.billboard_top_100_year_end
WHERE group_name ILIKE '%M.C.%'

SELECT *
FROM tutorial.billboard_top_100_year_end
WHERE group_name ILIKE '%hammer%'

/* need to exclude Jan Hammer from there */
SELECT *
FROM tutorial.billboard_top_100_year_end
WHERE (group_name ILIKE '%hammer%' OR group_name ILIKE '%elvis%') AND NOT group_name LIKE 'Jan Hammer'

SELECT *
FROM tutorial.billboard_top_100_year_end
WHERE year BETWEEN 1985 AND 1990

SELECT *
FROM tutorial.billboard_top_100_year_end
WHERE song_name IS NULL 

SELECT *
FROM tutorial.billboard_top_100_year_end
WHERE group_name ILIKE '%ludacris%' AND year_rank <= 10

SELECT *
FROM tutorial.billboard_top_100_year_end
WHERE year_rank = 1 AND year IN (1990, 2000, 2010)

SELECT *
FROM tutorial.billboard_top_100_year_end
WHERE song_name ILIKE '%love%' AND year BETWEEN 1960 AND 1969

SELECT *
FROM tutorial.billboard_top_100_year_end
WHERE year_rank <= 10 AND (group_name ILIKE '%katy perry%' OR group_name ILIKE '%jovi%')

SELECT *
FROM tutorial.billboard_top_100_year_end
WHERE song_name ILIKE '%california%' AND (year BETWEEN 1970 AND 1979 OR year BETWEEN 1990 AND 1999)

SELECT *
FROM tutorial.billboard_top_100_year_end
WHERE group_name ILIKE '%dr. dre%' AND (year <= 2000 OR year >= 2010)

SELECT *
FROM tutorial.billboard_top_100_year_end
WHERE year = 2013 AND song_name NOT ILIKE '%a%'

SELECT *
FROM tutorial.billboard_top_100_year_end
WHERE year = 2012
ORDER BY song_name DESC

SELECT *
FROM tutorial.billboard_top_100_year_end
WHERE year = 2010
ORDER BY year_rank ASC, artist ASC

SELECT *
FROM tutorial.billboard_top_100_year_end
WHERE group_name ILIKE '%t-pain%'
ORDER BY year_rank ASC

SELECT * -- selects all columns
FROM tutorial.billboard_top_100_year_end -- picks the set of data we work with
WHERE year_rank BETWEEN 10 AND 20 AND year IN (1993, 2003, 2013) -- picks our years and year ranks we want
ORDER BY year ASC, year_rank ASC -- orders by ascending year and then ascending rank

SELECT * 
FROM tutorial.aapl_historical_stock_price

SELECT COUNT(*)
  FROM tutorial.aapl_historical_stock_price
  
SELECT COUNT(high)
  FROM tutorial.aapl_historical_stock_price
  
  SELECT COUNT(date) AS size_of_date_column
  FROM tutorial.aapl_historical_stock_price
  
SELECT COUNT(date) AS date_count, COUNT(year) AS year_count, COUNT(month) AS month_count, COUNT(open) AS open_count,
COUNT(high) AS high_count, COUNT(low) AS low_count, COUNT(close) AS close_count, COUNT(volume) AS volume_count, COUNT(id) AS id_count
FROM tutorial.aapl_historical_stock_price

-- for this one, we seek the mean opening price of Apple stock over the course of the data
SELECT count(open) AS number_of_opening_stocks, sum(open) AS total_value_opening_stocks, (sum(open) / count(open)) AS mean_opening_value
FROM tutorial.aapl_historical_stock_price

SELECT min(low) AS lowest_apple_stock
FROM tutorial.aapl_historical_stock_price

SELECT max(close - open) AS largest_single_day_increase
FROM tutorial.aapl_historical_stock_price

SELECT avg(volume) AS avg_number_traded_stocks
FROM tutorial.aapl_historical_stock_price

SELECT year, COUNT(*) AS total
  FROM tutorial.aapl_historical_stock_price
 GROUP BY year
 
SELECT * 
FROM tutorial.aapl_historical_stock_price
 
SELECT year, month, COUNT(*) AS total
  FROM tutorial.aapl_historical_stock_price
 GROUP BY year, month
 ORDER BY year, month
 
  SELECT year, month, sum(volume) AS total_volume
  FROM tutorial.aapl_historical_stock_price
 GROUP BY year, month
 ORDER BY year ASC, month ASC
 
-- Write a query to calculate the average daily price change in Apple stock, grouped by year.
SELECT year, avg(close - open) AS mean_daily_change
FROM tutorial.aapl_historical_stock_price
GROUP BY year
ORDER BY year ASC

-- Write a query that calculates the lowest and highest prices that Apple stock achieved each month.
SELECT year, month, min(low) AS lowest_stock_value, max(high) AS highest_stock_value
FROM tutorial.aapl_historical_stock_price
GROUP BY year, month
ORDER BY year ASC, month ASC
 
SELECT * 
FROM benn.college_football_players

SELECT player_name, year, 
CASE WHEN year = 'SR' THEN 'yes' 
ELSE NULL END AS is_a_senior 
FROM benn.college_football_players

-- Write a query that includes a column that is flagged "yes" when a player is from California, and sort the results with those players first
SELECT *, 
CASE WHEN state = 'CA' THEN 'California'
ELSE 'Not CA' END AS from_california
FROM benn.college_football_players 
ORDER BY from_california ASC 

-- Write a query that includes players' names and a column that classifies them into four categories based on height
-- For this purpose, don't worry about data entry errors where players have height listed as 0
SELECT *,
CASE WHEN height >= 76 THEN 'Tall'
WHEN height >= 73 AND height <= 75 THEN 'Above Avg'
WHEN height >= 70 AND height <= 72 THEN 'Below Avg'
ELSE 'Small' END AS height_group 
FROM benn.college_football_players

-- Write a query that selects all columns from benn.college_football_players and adds an additional column that displays the player's name if that player is a junior or senior
SELECT *,
CASE WHEN year = 'JR' OR year = 'SR' THEN player_name
ELSE NULL END AS upperclass
FROM benn.college_football_players

SELECT CASE WHEN year = 'FR' THEN 'FR'
            WHEN year = 'SO' THEN 'SO'
            WHEN year = 'JR' THEN 'JR'
            WHEN year = 'SR' THEN 'SR'
            ELSE 'No Year Data' END AS year_group,
            COUNT(1) AS count
  FROM benn.college_football_players
 GROUP BY 1
 
 SELECT CASE WHEN year = 'FR' THEN 'FR'
            WHEN year = 'SO' THEN 'SO'
            WHEN year = 'JR' THEN 'JR'
            WHEN year = 'SR' THEN 'SR'
            ELSE 'No Year Data' END AS year_group,
            COUNT(1) AS count
  FROM benn.college_football_players
 GROUP BY year_group
 
 SELECT CASE WHEN year = 'FR' OR year = 'SO' THEN 'Underclass'
            WHEN year = 'JR' OR year = 'SR' THEN 'Upperclass'
            ELSE 'No Year Data' END AS year_group,
            *
  FROM benn.college_football_players
  
-- Write a query that counts the number of 300lb+ players for each of the following regions: West Coast (CA, OR, WA), Texas, and Other (everywhere else).
SELECT CASE WHEN weight >= 300 AND state IN ('CA', 'OR', 'WA') THEN 'Heavy-West'
WHEN weight >= 300 AND state = 'TX' THEN 'Heavy-Texas'
WHEN weight >= 300 THEN 'Heavy-Elsewhere'
WHEN weight >= 1 AND weight <= 299 THEN 'Under 300'
ELSE 'No Weight Data' END AS weight_state_combo,
COUNT(1) AS numeric_count
FROM benn.college_football_players
GROUP BY weight_state_combo

-- This accomplishes more or less the same thing, but filters only the players at 300+ pounds
SELECT CASE WHEN state IN ('CA', 'OR', 'WA') THEN 'West Coast'
WHEN state = 'TX' THEN 'Texas'
ELSE 'Other' END AS regional_designation,
COUNT(1) AS players
FROM benn.college_football_players
WHERE weight >= 300
GROUP BY regional_designation

-- Write a query that calculates the combined weight of all underclass players (FR/SO) in CA as well as the combined weight of all upperclass players (JR/SR) in CA.
SELECT CASE WHEN year = 'FR' OR year = 'SO' THEN 'Underclass'
WHEN year = 'JR' OR year = 'SR' THEN 'Upperclass'
ELSE 'No Year Data' END AS year_group,
SUM(weight) AS sum_weight
FROM benn.college_football_players
WHERE state = 'CA'
GROUP BY year_group

-- Write a query that displays the number of players in each state, with FR, SO, JR, and SR players in separate columns,
-- and another column for the total number of players. Order results such that states with the most players come first.
SELECT state,
COUNT(CASE WHEN year = 'FR' THEN 1 ELSE NULL END) AS fr_count,
COUNT(CASE WHEN year = 'SO' THEN 1 ELSE NULL END) AS so_count,
COUNT(CASE WHEN year = 'JR' THEN 1 ELSE NULL END) AS jr_count,
COUNT(CASE WHEN year = 'SR' THEN 1 ELSE NULL END) AS sr_count,
COUNT(state) AS total_players_state
FROM benn.college_football_players
GROUP BY state
ORDER BY total_players_state DESC

-- Write a query that shows the number of players at schools with names that start with A through M, and the number at schools with names starting with N - Z.
SELECT CASE WHEN school_name < 'N' THEN 'early_alphabet'
WHEN school_name > 'M' THEN 'late_alphabet'
ELSE NULL END AS school_alphabet_range,
COUNT(1) AS numeric_count_players
FROM benn.college_football_players
GROUP BY school_alphabet_range

SELECT DISTINCT year, month
  FROM tutorial.aapl_historical_stock_price
  ORDER BY year ASC, month ASC
  
SELECT COUNT(DISTINCT month) AS unique_months
FROM tutorial.aapl_historical_stock_price

SELECT month,
       AVG(volume) AS avg_trade_volume
  FROM tutorial.aapl_historical_stock_price
 GROUP BY month
 ORDER BY avg_trade_volume DESC
 
-- Write a query that counts the number of unique values in the month column for each year.
SELECT year, COUNT(DISTINCT month) AS unique_months
FROM tutorial.aapl_historical_stock_price
GROUP BY year 
ORDER BY year ASC

-- Write a query that separately counts the number of unique values in the month column and the number of unique values in the `year` column.
SELECT COUNT(DISTINCT month) AS unique_months,
COUNT(DISTINCT year) AS unique_years
FROM tutorial.aapl_historical_stock_price 

SELECT teams.conference AS conference,
       AVG(players.weight) AS average_weight
  FROM benn.college_football_players players
  JOIN benn.college_football_teams teams
    ON teams.school_name = players.school_name
 GROUP BY teams.conference
 ORDER BY AVG(players.weight) DESC
 
SELECT *
FROM benn.college_football_players
 
SELECT *
FROM benn.college_football_teams
 
-- Write a query that selects the school name, player name, position, and weight for every player in Georgia
-- ordered by weight (heaviest to lightest). Be sure to make an alias for the table, and to reference all column names in relation to the alias.
 
-- The prompt did NOT ask for conference, so we don't need the teams data set (yet)
-- Also I assume the prompt meant players whose hometowns were in Georgia, not players on UGA roster
SELECT full_school_name, player_name, position, weight
FROM benn.college_football_players players
WHERE state = 'GA'
ORDER BY weight DESC

SELECT *
  FROM benn.college_football_players players
  JOIN benn.college_football_teams teams
    ON teams.school_name = players.school_name

-- Write a query that displays player names, school names and conferences for schools in the "FBS (Division I-A Teams)" division.
SELECT players.full_school_name, players.player_name, teams.conference
FROM benn.college_football_players players
JOIN benn.college_football_teams teams
ON teams.school_name = players.school_name
WHERE teams.division = 'FBS (Division I-A Teams)'

SELECT *
  FROM tutorial.crunchbase_companies
  
SELECT *
  FROM tutorial.crunchbase_acquisitions
  
SELECT *
FROM tutorial.crunchbase_companies companies
LEFT JOIN tutorial.crunchbase_acquisitions acquisitions 
ON companies.permalink = acquisitions.company_permalink 

SELECT *
FROM tutorial.crunchbase_companies companies
JOIN tutorial.crunchbase_acquisitions acquisitions
ON companies.permalink = acquisitions.company_permalink

SELECT companies.permalink AS companies_permalink,
       companies.name AS companies_name,
       acquisitions.company_permalink AS acquisitions_permalink,
       acquisitions.acquired_at AS acquired_date
  FROM tutorial.crunchbase_companies companies
  LEFT JOIN tutorial.crunchbase_acquisitions acquisitions
    ON companies.permalink = acquisitions.company_permalink

-- Write a query that performs an inner join between the tutorial.crunchbase_acquisitions table and the tutorial.crunchbase_companies table
-- But instead of listing individual rows, count the number of non-null rows in each table (referring to just the permalink columns)
SELECT COUNT(companies.permalink) AS companies_rowcount,
       COUNT(acquisitions.company_permalink) AS acquisitions_rowcount
  FROM tutorial.crunchbase_companies companies
  JOIN tutorial.crunchbase_acquisitions acquisitions
    ON companies.permalink = acquisitions.company_permalink
    
-- Now do the same with LEFT JOIN instead of JOIN, and observe the different results
SELECT COUNT(companies.permalink) AS companies_rowcount,
  COUNT(acquisitions.company_permalink) AS acquisitions_rowcount
  FROM tutorial.crunchbase_companies companies
  LEFT JOIN tutorial.crunchbase_acquisitions acquisitions
    ON companies.permalink = acquisitions.company_permalink

SELECT COUNT(companies.permalink) AS companies_rowcount,
  COUNT(acquisitions.company_permalink) AS acquisitions_rowcount
  FROM tutorial.crunchbase_acquisitions acquisitions
  RIGHT JOIN tutorial.crunchbase_companies companies
    ON companies.permalink = acquisitions.company_permalink

-- Count the number of unique companies (don't double-count companies) and unique acquired companies by state
-- Do not include results for which there is no state data, and order by the number of acquired companies from highest to lowest.
SELECT COUNT(DISTINCT companies.name) AS total_company_names_count,
COUNT(DISTINCT acquisitions.company_name) AS acquired_company_names_count,
companies.state_code AS state
FROM tutorial.crunchbase_companies companies
FULL JOIN tutorial.crunchbase_acquisitions acquisitions
ON companies.permalink = acquisitions.company_permalink
WHERE companies.state_code IS NOT NULL
GROUP BY companies.state_code
ORDER BY acquired_company_names_count DESC 

SELECT companies.permalink AS companies_permalink,
       companies.name AS companies_name,
       acquisitions.company_permalink AS acquisitions_permalink,
       acquisitions.acquired_at AS acquired_date
  FROM tutorial.crunchbase_companies companies
  LEFT JOIN tutorial.crunchbase_acquisitions acquisitions
    ON companies.permalink = acquisitions.company_permalink
   AND acquisitions.company_permalink != '/company/1000memories'
 ORDER BY companies_permalink
 
SELECT *
  FROM tutorial.crunchbase_companies
  
SELECT *
  FROM tutorial.crunchbase_acquisitions
  
SELECT *
  FROM tutorial.crunchbase_investments
  
SELECT *
  FROM tutorial.crunchbase_investments_part1
  
-- Write a query that shows a company's name, its "status" (found in the Companies table), and the number of unique investors in that company.
-- Order by the number of investors from most to fewest. Limit to only companies in the state of New York.
-- What's important is that company_permalink in the tutorial.crunchbase_investments table maps to permalink in the tutorial.crunchbase_companies table.
SELECT companies.name AS name,
companies.status AS status,
COUNT(DISTINCT investments.investor_name) AS investor_name_count
FROM tutorial.crunchbase_investments investments
LEFT JOIN tutorial.crunchbase_companies companies
ON companies.permalink = investments.company_permalink
WHERE companies.state_code = 'NY'
GROUP BY name, status
ORDER BY investor_name_count DESC 

-- Write a query that lists investors based on the number of companies in which they are invested. 
-- Include a row for companies with no investor, and order from most companies to least.
SELECT investments.investor_name as investor_name,
COUNT(companies.name) as company_count
FROM tutorial.crunchbase_companies companies
LEFT JOIN tutorial.crunchbase_investments investments
ON companies.permalink = investments.company_permalink 
-- WHERE investor_name IS NOT NULL
GROUP BY investor_name
ORDER BY company_count DESC 

-- This is a version of that, which actually renames the NULL rows
SELECT CASE WHEN investments.investor_name IS NULL THEN 'No Investors'
            ELSE investments.investor_name END AS investor,
       COUNT(DISTINCT companies.permalink) AS companies_invested_in
  FROM tutorial.crunchbase_companies companies
  LEFT JOIN tutorial.crunchbase_investments investments
    ON companies.permalink = investments.company_permalink
 GROUP BY investor
 ORDER BY companies_invested_in DESC
 
 SELECT COUNT(CASE WHEN companies.permalink IS NOT NULL AND acquisitions.company_permalink IS NULL
                  THEN companies.permalink ELSE NULL END) AS companies_only_count,
       COUNT(CASE WHEN companies.permalink IS NOT NULL AND acquisitions.company_permalink IS NOT NULL
                  THEN companies.permalink ELSE NULL END) AS count_in_both_tables,
       COUNT(CASE WHEN companies.permalink IS NULL AND acquisitions.company_permalink IS NOT NULL
                  THEN acquisitions.company_permalink ELSE NULL END) AS acquisitions_only_count
  FROM tutorial.crunchbase_companies companies
  FULL JOIN tutorial.crunchbase_acquisitions acquisitions
    ON companies.permalink = acquisitions.company_permalink
   
-- Write a query that joins tutorial.crunchbase_companies and tutorial.crunchbase_investments_part1 using a FULL JOIN. 
-- Count up the number of rows that are matched/unmatched as in the example above.
SELECT COUNT(CASE WHEN companies.permalink IS NOT NULL AND investments.company_permalink IS NULL
                  THEN companies.permalink ELSE NULL END) AS companies_only_count,
       COUNT(CASE WHEN companies.permalink IS NOT NULL AND investments.company_permalink IS NOT NULL
                  THEN companies.permalink ELSE NULL END) AS count_in_both_tables,
       COUNT(CASE WHEN companies.permalink IS NULL AND investments.company_permalink IS NOT NULL
                  THEN investments.company_permalink ELSE NULL END) AS investments_only_count
  FROM tutorial.crunchbase_companies companies
  FULL JOIN tutorial.crunchbase_investments_part1 investments
    ON companies.permalink = investments.company_permalink
  
SELECT *
  FROM tutorial.crunchbase_investments_part1

 UNION

 SELECT *
   FROM tutorial.crunchbase_investments_part2

-- Write a query that appends the two crunchbase_investments datasets above (including duplicate values). 
-- Filter the first dataset to only companies with names that start with the letter "T", and filter the second to companies with names starting with "M" (both not case-sensitive). 
-- Only include the company_permalink, company_name, and investor_name columns.
SELECT company_permalink, company_name, investor_name
FROM tutorial.crunchbase_investments_part1
WHERE company_name ILIKE 'T%'

UNION ALL

SELECT company_permalink, company_name, investor_name
FROM tutorial.crunchbase_investments_part2
WHERE company_name ILIKE 'M%'

-- Write a query that shows 3 columns
-- The first indicates which dataset (part 1 or 2) the data comes from, the second shows company status, and the third is a count of the number of investors.
-- Hint: you will have to use the tutorial.crunchbase_companies table as well as the investments tables. And you'll want to group by status and dataset.

-- First left join Part 1 with companies, then repeat that with Part 2 and companies, then use UNION ALL to stack those together
SELECT 'Part 1' AS sql_dataset, companies.status AS status, 
COUNT(DISTINCT investments_part1.investor_name) AS investor_count
FROM tutorial.crunchbase_investments_part1 investments_part1
LEFT JOIN tutorial.crunchbase_companies companies 
ON companies.permalink = investments_part1.company_permalink 
WHERE status IS NOT NULL 
GROUP BY status, sql_dataset

UNION ALL 

SELECT 'Part 2' AS sql_dataset, companies.status AS status, 
COUNT(DISTINCT investments_part2.investor_name) AS investor_count
FROM tutorial.crunchbase_investments_part2 investments_part2
LEFT JOIN tutorial.crunchbase_companies companies 
ON companies.permalink = investments_part2.company_permalink 
WHERE status IS NOT NULL 
GROUP BY status, sql_dataset

SELECT ROW_NUMBER() OVER (
            ORDER BY weight DESC, height DESC
    ) weight_rank, *
FROM benn.college_football_players

SELECT *
FROM tutorial.crunchbase_companies_clean_date

SELECT *, CAST(funding_total_usd AS VARCHAR) AS funding_total_usd_VARCHAR
FROM tutorial.crunchbase_companies_clean_date 

SELECT permalink,
       founded_at,
       founded_at_clean
  FROM tutorial.crunchbase_companies_clean_date
 ORDER BY founded_at_clean
 
SELECT companies.permalink,
       companies.founded_at_clean,
       acquisitions.acquired_at_cleaned,
       acquisitions.acquired_at_cleaned - companies.founded_at_clean::TIMESTAMP AS time_to_acquisition
  FROM tutorial.crunchbase_companies_clean_date companies
  JOIN tutorial.crunchbase_acquisitions_clean_date acquisitions
    ON acquisitions.company_permalink = companies.permalink
 WHERE founded_at_clean IS NOT NULL
 
SELECT companies.permalink,
       companies.founded_at_clean,
       companies.founded_at_clean::timestamp +
         INTERVAL '1 week' AS founding_time_plus_one_week
  FROM tutorial.crunchbase_companies_clean_date companies
 WHERE founded_at_clean IS NOT NULL
 
-- Write a query that counts the number of companies acquired within 3 years, 5 years, and 10 years of being founded (in 3 separate columns)
-- Include a column for total companies acquired as well. Group by category and limit to only rows with a founding date.
SELECT *
FROM tutorial.crunchbase_companies_clean_date companies
-- Use permalink, founded_at_clean, category_code

SELECT *
FROM tutorial.crunchbase_acquisitions_clean_date acquisitions
-- use company_permalink, acquired_at_cleaned

-- This isn't actually the final answer, but just showing how to get the "indicators" for any given row
SELECT companies.permalink, companies.founded_at_clean, acquisitions.company_permalink, acquisitions.acquired_at_cleaned, companies.category_code,
acquisitions.acquired_at_cleaned - companies.founded_at_clean::TIMESTAMP AS time_to_acquisition,
CASE WHEN (acquisitions.acquired_at_cleaned - companies.founded_at_clean::TIMESTAMP) < '3 years' THEN 'within_three_years' 
ELSE 'over_three_years' END AS three_year_indicator,
CASE WHEN (acquisitions.acquired_at_cleaned - companies.founded_at_clean::TIMESTAMP) < '5 years' THEN 'within_five_years' 
ELSE 'over_five_years' END AS five_year_indicator,
CASE WHEN (acquisitions.acquired_at_cleaned - companies.founded_at_clean::TIMESTAMP) < '10 years' THEN 'within_ten_years' 
ELSE 'over_ten_years' END AS ten_year_indicator
FROM tutorial.crunchbase_acquisitions_clean_date acquisitions  
JOIN tutorial.crunchbase_companies_clean_date companies -- in this case we only want companies that were in both data sets
ON companies.permalink = acquisitions.company_permalink 
WHERE founded_at_clean IS NOT NULL 
AND acquired_at_cleaned IS NOT NULL
AND (acquisitions.acquired_at_cleaned - companies.founded_at_clean::TIMESTAMP) > '0 seconds'

-- Now get the actual final answer
SELECT companies.category_code,
COUNT(CASE WHEN (acquisitions.acquired_at_cleaned - companies.founded_at_clean::TIMESTAMP) < '3 years' THEN 1
ELSE NULL END) AS within_three_years_count,
COUNT(CASE WHEN (acquisitions.acquired_at_cleaned - companies.founded_at_clean::TIMESTAMP) < '5 years' THEN 1
ELSE NULL END) AS within_five_years_count,
COUNT(CASE WHEN (acquisitions.acquired_at_cleaned - companies.founded_at_clean::TIMESTAMP) < '10 years' THEN 1
ELSE NULL END) AS within_ten_years_count,
COUNT(companies.category_code) AS total_acquisitions_in_category
FROM tutorial.crunchbase_acquisitions_clean_date acquisitions  
JOIN tutorial.crunchbase_companies_clean_date companies -- in this case we only want companies that were in both data sets
ON companies.permalink = acquisitions.company_permalink 
WHERE founded_at_clean IS NOT NULL 
AND acquired_at_cleaned IS NOT NULL
AND (acquisitions.acquired_at_cleaned - companies.founded_at_clean::TIMESTAMP) > '0 seconds'
GROUP BY companies.category_code
ORDER BY total_acquisitions_in_category DESC 

SELECT *
  FROM tutorial.sf_crime_incidents_2014_01

SELECT incidnt_num,
       date,
       LEFT(date, 10) AS cleaned_date,
       RIGHT(date, 17) AS cleaned_time
  FROM tutorial.sf_crime_incidents_2014_01
  
SELECT incidnt_num,
       date,
       LEFT(date, 10) AS cleaned_date,
       RIGHT(date, LENGTH(date) - 11) AS cleaned_time
  FROM tutorial.sf_crime_incidents_2014_01
  
SELECT location,
TRIM(both '()' FROM location) AS trimmed_location
FROM tutorial.sf_crime_incidents_2014_01

SELECT incidnt_num,
       date,
       SUBSTR(date, 4, 2) AS day_of_month
  FROM tutorial.sf_crime_incidents_2014_01
  
-- Write a query that separates the `location` field into separate fields for latitude and longitude. 
-- You can compare your results against the actual `lat` and `lon` fields in the table.
SELECT incidnt_num, lat, lon, location,
       TRIM(leading '()' FROM LEFT(location, POSITION(',' IN location) - 1)) AS new_latitude,
       TRIM(trailing '()' FROM RIGHT(location, LENGTH(location) - POSITION(',' IN location) ) ) AS new_longitude
FROM tutorial.sf_crime_incidents_2014_01

SELECT incidnt_num,
       day_of_week,
       LEFT(date, 10) AS cleaned_date,
       CONCAT(day_of_week, ', ', LEFT(date, 10)) AS day_of_week_with_date
  FROM tutorial.sf_crime_incidents_2014_01
  
-- Concatenate the lat and lon fields to form a field that is equivalent to the location field.
-- (Note that the answer will have a different decimal precision.)
SELECT incidnt_num, lat, lon, location,
CONCAT('(', lat, ', ', lon, ')') AS adjusted_location
FROM tutorial.sf_crime_incidents_2014_01

-- Write a query that creates a date column formatted YYYY-MM-DD from the same data set
SELECT incidnt_num, 
CONCAT(SUBSTR(date, 7, 4), '-', SUBSTR(date, 1, 2), '-', SUBSTR(date, 4, 2)) AS proper_date
FROM tutorial.sf_crime_incidents_2014_01

-- Repeat that, but now also convert the data type into TIMESTAMP
-- Write a query that creates a date column formatted YYYY-MM-DD from the same data set
SELECT incidnt_num, 
CAST(CONCAT(SUBSTR(date, 7, 4), '-', SUBSTR(date, 1, 2), '-', SUBSTR(date, 4, 2)) AS TIMESTAMP) AS proper_date
FROM tutorial.sf_crime_incidents_2014_01

SELECT incidnt_num,
       address,
       UPPER(address) AS address_upper,
       LOWER(address) AS address_lower
  FROM tutorial.sf_crime_incidents_2014_01
  
-- Write a query that returns the `category` field, but with the first letter capitalized and the rest of the letters in lower-case.
SELECT incidnt_num, category,
CONCAT(UPPER(LEFT(category, 1)), LOWER(RIGHT(category, LENGTH(category) - 1))) AS proper_category
FROM tutorial.sf_crime_incidents_2014_01

-- Write a query that creates an accurate timestamp using the date and time columns in tutorial.sf_crime_incidents_2014_01. 
-- Include a field that is exactly 1 week later as well.
SELECT incidnt_num, 
CAST(CONCAT(SUBSTR(date, 7, 4), '-', SUBSTR(date, 1, 2), '-', SUBSTR(date, 4, 2), ' ', time) AS TIMESTAMP) AS proper_date_and_time,
CAST(CONCAT(SUBSTR(date, 7, 4), '-', SUBSTR(date, 1, 2), '-', SUBSTR(date, 4, 2), ' ', time) AS TIMESTAMP) + INTERVAL '1 week' AS one_week_after_incident
FROM tutorial.sf_crime_incidents_2014_01

SELECT cleaned_date,
       EXTRACT('year'   FROM cleaned_date) AS year,
       EXTRACT('month'  FROM cleaned_date) AS month,
       EXTRACT('day'    FROM cleaned_date) AS day,
       EXTRACT('hour'   FROM cleaned_date) AS hour,
       EXTRACT('minute' FROM cleaned_date) AS minute,
       EXTRACT('second' FROM cleaned_date) AS second,
       CONCAT(EXTRACT('decade' FROM cleaned_date), '0s') AS decade,
       EXTRACT('dow'    FROM cleaned_date) AS day_of_week
  FROM tutorial.sf_crime_incidents_cleandate
  
  SELECT cleaned_date,
       DATE_TRUNC('year'   , cleaned_date) AS nearest_year,
       DATE_TRUNC('month'  , cleaned_date) AS nearest_month,
       DATE_TRUNC('week'   , cleaned_date) AS nearest_week,
       DATE_TRUNC('day'    , cleaned_date) AS nearest_day,
       DATE_TRUNC('hour'   , cleaned_date) AS nearest_hour,
       DATE_TRUNC('minute' , cleaned_date) AS nearest_minute,
       DATE_TRUNC('second' , cleaned_date) AS nearest_second,
       DATE_TRUNC('decade' , cleaned_date) AS nearest_decade
  FROM tutorial.sf_crime_incidents_cleandate
  
-- Write a query that counts the number of incidents reported by week. Cast the week as a date to get rid of the hours/minutes/seconds.
SELECT *
  FROM tutorial.sf_crime_incidents_cleandate

SELECT COUNT(incidnt_num) AS incident_number,
CAST(DATE_TRUNC('week'   , cleaned_date) AS TIMESTAMP) AS nearest_week
FROM tutorial.sf_crime_incidents_cleandate
GROUP BY nearest_week
ORDER BY incident_number DESC 

SELECT CURRENT_DATE AS date,
       CURRENT_TIME AS time,
       CURRENT_TIMESTAMP AS timestamp,
       LOCALTIME AS localtime,
       LOCALTIMESTAMP AS localtimestamp,
       NOW() AS now

SELECT CURRENT_TIME AS time,
CURRENT_TIME AT TIME ZONE 'PST' AS time_pst

-- Write a query that shows exactly how long ago each incident was reported. Assume that the dataset is in Pacific Standard Time (UTC - 8).
SELECT incidnt_num, 
CAST(CONCAT(SUBSTR(date, 7, 4), '-', SUBSTR(date, 1, 2), '-', SUBSTR(date, 4, 2), ' ', time) AS TIMESTAMP) AS proper_date_and_time,
NOW() AT TIME ZONE 'PST' AS now,
NOW() AT TIME ZONE 'PST' - CAST(CONCAT(SUBSTR(date, 7, 4), '-', SUBSTR(date, 1, 2), '-', SUBSTR(date, 4, 2), ' ', time) AS TIMESTAMP) AS time_elapsed_since_incident
FROM tutorial.sf_crime_incidents_2014_01

-- OR
SELECT incidnt_num, cleaned_date,
NOW() AT TIME ZONE 'PST' AS now,
NOW() AT TIME ZONE 'PST' - cleaned_date AS time_elapsed_since_incident
FROM tutorial.sf_crime_incidents_cleandate

SELECT incidnt_num,
       descript,
       COALESCE(descript, 'No Description') AS fixed_descript
  FROM tutorial.sf_crime_incidents_cleandate
 ORDER BY descript DESC
 
SELECT sub.*
  FROM (
        SELECT *
          FROM tutorial.sf_crime_incidents_2014_01
         WHERE day_of_week = 'Friday'
       ) sub
 WHERE sub.resolution = 'NONE'
 
 
-- Write a query that selects all Warrant Arrests from the tutorial.sf_crime_incidents_2014_01 dataset,
-- then wrap it in an outer query that only displays unresolved incidents.
SELECT sub.*
FROM (
        SELECT *
          FROM tutorial.sf_crime_incidents_2014_01
         WHERE descript = 'WARRANT ARREST'
       ) sub
WHERE sub.resolution = 'NONE'

SELECT LEFT(sub.date, 2) AS cleaned_month,
       sub.day_of_week,
       AVG(sub.incidents) AS average_incidents
  FROM (
        SELECT date,
               day_of_week,
               COUNT(incidnt_num) AS incidents
          FROM tutorial.sf_crime_incidents_2014_01
         GROUP BY 1,2
       ) sub
 GROUP BY 1,2
 ORDER BY 1,2
 
SELECT * 
FROM tutorial.sf_crime_incidents_cleandate
-- Write a query that displays the average number of monthly incidents for each category (from the category column)
-- Hint: use tutorial.sf_crime_incidents_cleandate to make your life a little easier.
SELECT LEFT(sub.date, 2) AS cleaned_month,
       sub.category,
       AVG(sub.incidents) AS average_incidents
  FROM (
        SELECT date,
               category,
               COUNT(incidnt_num) AS incidents
          FROM tutorial.sf_crime_incidents_cleandate
         GROUP BY date, category
       ) sub
 GROUP BY cleaned_month, category
 ORDER BY cleaned_month, category
 
SELECT *
  FROM tutorial.sf_crime_incidents_2014_01
 WHERE Date IN (SELECT date
                 FROM tutorial.sf_crime_incidents_2014_01
                ORDER BY date
                LIMIT 5
              )
              
SELECT *
  FROM tutorial.sf_crime_incidents_2014_01 incidents
  JOIN ( SELECT date
           FROM tutorial.sf_crime_incidents_2014_01
          ORDER BY date
          LIMIT 5
       ) sub
    ON incidents.date = sub.date
    
SELECT incidents.*,
       sub.incidents_that_day
  FROM tutorial.sf_crime_incidents_2014_01 incidents
  JOIN ( SELECT date,
          COUNT(incidnt_num) AS incidents_that_day
           FROM tutorial.sf_crime_incidents_2014_01
          GROUP BY date
       ) sub
    ON incidents.date = sub.date
 ORDER BY sub.incidents_that_day DESC, time
 
-- Write a query that displays all rows from the three categories with the fewest incidents reported.
SELECT incidents.*, sub.incident_count AS incident_count_in_category
  FROM tutorial.sf_crime_incidents_2014_01 incidents
  JOIN ( SELECT category, COUNT(*) as incident_count
           FROM tutorial.sf_crime_incidents_2014_01
           GROUP BY category
          ORDER BY incident_count ASC
          LIMIT 3
       ) sub
    ON incidents.category = sub.category
    
SELECT COALESCE(acquisitions.month, investments.month) AS month,
       acquisitions.companies_acquired,
       investments.companies_receiving_investment
  FROM (
        SELECT acquired_month AS month,
               COUNT(DISTINCT company_permalink) AS companies_acquired
          FROM tutorial.crunchbase_acquisitions
         GROUP BY month
       ) acquisitions

  FULL JOIN (
        SELECT funded_month AS month,
               COUNT(DISTINCT company_permalink) AS companies_receiving_investment
          FROM tutorial.crunchbase_investments
         GROUP BY month
       ) investments

    ON acquisitions.month = investments.month
 ORDER BY month DESC
 
SELECT *
FROM tutorial.crunchbase_acquisitions

SELECT *
FROM tutorial.crunchbase_companies

SELECT *
FROM tutorial.crunchbase_investments
-- Write a query that counts the number of companies founded and acquired by quarter starting in Q1 2012 - use acquired_quarter and founded_quarter
-- Create the aggregations in two separate queries, then join them.
SELECT COALESCE(acquisitions.quarter, companies.quarter) AS quarter,
       acquisitions.companies_acquired,
       companies.companies_founded
  FROM (
        SELECT acquired_quarter AS quarter,
               COUNT(DISTINCT company_permalink) AS companies_acquired
          FROM tutorial.crunchbase_acquisitions
          WHERE acquired_quarter >= '2012-Q1'
         GROUP BY quarter
       ) acquisitions

  FULL JOIN (
        SELECT founded_quarter AS quarter,
               COUNT(DISTINCT permalink) AS companies_founded
          FROM tutorial.crunchbase_companies
          WHERE founded_quarter >= '2012-Q1'
         GROUP BY quarter
       ) companies

    ON acquisitions.quarter = companies.quarter
 ORDER BY quarter DESC
 
SELECT COUNT(*) AS total_rows
  FROM (
        SELECT *
          FROM tutorial.crunchbase_investments_part1

         UNION ALL

        SELECT *
          FROM tutorial.crunchbase_investments_part2
       ) sub
       
-- Write a query that ranks investors from the combined dataset above by the total number of investments they have made -- use investor_name and company_permalink
SELECT investor_name AS investor,
COUNT(DISTINCT company_permalink) AS total_investments
  FROM (
        SELECT *
          FROM tutorial.crunchbase_investments_part1

         UNION ALL

        SELECT *
          FROM tutorial.crunchbase_investments_part2
       ) sub
GROUP BY investor
ORDER BY total_investments DESC

-- Write a query that does the same thing as in the previous problem, except only for companies that are still operating. 
-- Hint: operating status is in tutorial.crunchbase_companies, the status column
SELECT investments.investor_name,
       COUNT(investments.*) AS total_investments
  FROM tutorial.crunchbase_companies companies
  JOIN (
        SELECT *
          FROM tutorial.crunchbase_investments_part1
         
         UNION ALL
        
         SELECT *
           FROM tutorial.crunchbase_investments_part2
       ) investments
    ON investments.company_permalink = companies.permalink
 WHERE companies.status = 'operating'
 GROUP BY investor_name
 ORDER BY total_investments DESC
 
SELECT *
FROM tutorial.dc_bikeshare_q1_2012
 
SELECT duration_seconds,
       SUM(duration_seconds) OVER (ORDER BY start_time) AS running_total
 FROM tutorial.dc_bikeshare_q1_2012
 
 SELECT start_terminal,
       duration_seconds,
       SUM(duration_seconds) OVER
         (PARTITION BY start_terminal ORDER BY start_time)
         AS running_total
  FROM tutorial.dc_bikeshare_q1_2012
 WHERE start_time < '2012-01-08'
 
-- This version wouldn't be as informative, because the ORDER BY is excluded 
-- But still useful if we wanted to see how many total seconds ended up happening at each terminal
 SELECT start_terminal,
       duration_seconds,
       SUM(duration_seconds) OVER
         (PARTITION BY start_terminal) AS total_seconds_at_terminal -- NOT cumulative
  FROM tutorial.dc_bikeshare_q1_2012
 WHERE start_time < '2012-01-08'
 
-- Write a query modification of the above example query that shows the duration of each ride as a percentage of the total time accrued by riders from each start_terminal
SELECT start_terminal,
       duration_seconds,
       SUM(duration_seconds) OVER (PARTITION BY start_terminal) AS total_seconds_at_terminal, -- NOT cumulative
       (duration_seconds/SUM(duration_seconds) OVER (PARTITION BY start_terminal))*100 AS percentage_of_terminal_total
  FROM tutorial.dc_bikeshare_q1_2012
 WHERE start_time < '2012-01-08'
ORDER BY start_terminal, percentage_of_terminal_total DESC 
-- Only include final line if we'd rather order it by the rides that took up the longest proportion of time, rather than listing rides in chronological order

SELECT start_terminal,
       duration_seconds,
       SUM(duration_seconds) OVER
         (PARTITION BY start_terminal) AS total_seconds_at_terminal,
       COUNT(duration_seconds) OVER
         (PARTITION BY start_terminal) AS total_trips_at_terminal,
       AVG(duration_seconds) OVER
         (PARTITION BY start_terminal) AS seconds_per_trip_at_terminal
  FROM tutorial.dc_bikeshare_q1_2012
 WHERE start_time < '2012-01-08'
-- This example is NOT cumulative, b/c we didn’t include ORDER BY, so this example is more like adding the final drive result to each individual row in NFLFastR

-- In contrast, this one does include ORDER BY, so it does give us true running totals
SELECT start_terminal,
       duration_seconds,
       SUM(duration_seconds) OVER
         (PARTITION BY start_terminal ORDER BY start_time)
         AS running_total_sec,
       COUNT(duration_seconds) OVER
         (PARTITION BY start_terminal ORDER BY start_time)
         AS running_number_of_trips,
       AVG(duration_seconds) OVER
         (PARTITION BY start_terminal ORDER BY start_time)
         AS running_avg
  FROM tutorial.dc_bikeshare_q1_2012
 WHERE start_time < '2012-01-08'
 
-- Write a query that shows a running total of the duration of bike rides (similar to the last example)
-- But make it grouped by end_terminal, and with ride duration sorted in descending order.
-- In other words, this time we don't care about ordering the rides by start_time
SELECT end_terminal,
       duration_seconds,
       SUM(duration_seconds) OVER
         (PARTITION BY end_terminal ORDER BY duration_seconds DESC)
         AS running_total_sec
  FROM tutorial.dc_bikeshare_q1_2012
 WHERE start_time < '2012-01-08'
-- Keep in mind these results DON'T go in the chronological order that the train rides occurred

SELECT start_terminal,
       start_time,
       duration_seconds,
       ROW_NUMBER() OVER (ORDER BY start_time)
                    AS row_number
  FROM tutorial.dc_bikeshare_q1_2012
 WHERE start_time < '2012-01-08'
 
-- The above was a pretty basic example that simply gives the row number for each train ride in chronological order, 
-- without worrying about re-starting the count at new terminals or anything of that nature. 
-- In contrast, this one orders by the starting terminal, and resets the row_number count at 1 when we get to a new terminal: 
 SELECT start_terminal,
       start_time,
       duration_seconds,
       ROW_NUMBER() OVER (PARTITION BY start_terminal
                          ORDER BY start_time)
                    AS row_number
  FROM tutorial.dc_bikeshare_q1_2012
 WHERE start_time < '2012-01-08'
 
SELECT start_terminal,
       duration_seconds,
       RANK() OVER (PARTITION BY start_terminal
                    ORDER BY start_time)
              AS start_time_rank
  FROM tutorial.dc_bikeshare_q1_2012
 WHERE start_time < '2012-01-08'
 
-- Write a query that shows the 5 longest rides from each starting terminal, ordered by terminal, and longest to shortest rides within each terminal.
-- Limit to rides that occurred before Jan. 8, 2012.
SELECT *
  FROM (
        SELECT start_terminal,
               start_time,
               duration_seconds AS trip_time,
               RANK() OVER (PARTITION BY start_terminal ORDER BY duration_seconds DESC) AS duration_rank
          FROM tutorial.dc_bikeshare_q1_2012
         WHERE start_time < '2012-01-08'
               ) sub
 WHERE sub.duration_rank <= 5
 
SELECT start_terminal,
       duration_seconds,
       NTILE(4) OVER
         (PARTITION BY start_terminal ORDER BY duration_seconds)
          AS quartile,
       NTILE(5) OVER
         (PARTITION BY start_terminal ORDER BY duration_seconds)
         AS quintile,
       NTILE(100) OVER
         (PARTITION BY start_terminal ORDER BY duration_seconds)
         AS percentile
  FROM tutorial.dc_bikeshare_q1_2012
 WHERE start_time < '2012-01-08'
 ORDER BY start_terminal, duration_seconds
 
-- Write a query that shows only the duration of the trip and the percentile into which that duration falls (across the entire dataset—not partitioned by terminal).
SELECT start_terminal, duration_seconds,
       NTILE(100) OVER
         (ORDER BY duration_seconds)
         AS percentile
  FROM tutorial.dc_bikeshare_q1_2012
 WHERE start_time < '2012-01-08'
 ORDER BY duration_seconds
 
SELECT *
FROM tutorial.dc_bikeshare_q1_2012

SELECT start_terminal, start_time,
       duration_seconds,
       LAG(duration_seconds, 1) OVER
         (PARTITION BY start_terminal ORDER BY start_time) AS lag_duration,
       LEAD(duration_seconds, 1) OVER
         (PARTITION BY start_terminal ORDER BY start_time) AS lead_duration
  FROM tutorial.dc_bikeshare_q1_2012
 WHERE start_time < '2012-01-08'
 ORDER BY start_terminal, start_time
 
SELECT start_terminal, start_time,
       duration_seconds,
       duration_seconds - LAG(duration_seconds, 1) OVER
         (PARTITION BY start_terminal ORDER BY start_time)
         AS difference_in_duration
  FROM tutorial.dc_bikeshare_q1_2012
 WHERE start_time < '2012-01-08'
 ORDER BY start_terminal, start_time
 
-- This version uses an outer query to get rid of NULLs
SELECT * 
FROM ( 
	SELECT start_terminal, start_time, duration_seconds, 
	duration_seconds - LAG(duration_seconds, 1) OVER 
		(PARTITION BY start_terminal ORDER BY start_time) AS diff_in_duration 
	FROM tutorial.dc_bikeshare_q1_2012 
	WHERE start_time < '2012-01-08' 
	ORDER BY start_terminal, start_time
	) sub 
WHERE sub.diff_in_duration IS NOT NULL

-- The following two code snippets are equivalent, one uses the WINDOW clause to make it look cleaner
SELECT start_terminal, duration_seconds, 
NTILE(4) OVER 
	(PARTITION BY start_terminal ORDER BY duration_seconds) AS quartile, 
NTILE(5) OVER 
	(PARTITION BY start_terminal ORDER BY duration_seconds) AS quintile, 
NTILE(100) OVER 
	(PARTITION BY start_terminal ORDER BY duration_seconds) AS percentile 
FROM tutorial.dc_bikeshare_q1_2012 
WHERE start_time < '2012-01-08' 
ORDER BY start_terminal, duration_seconds

SELECT start_terminal, duration_seconds, 
NTILE(4) OVER ntile_window AS quartile, 
NTILE(5) OVER ntile_window AS quintile, 
NTILE(100) OVER ntile_window AS percentile 
FROM tutorial.dc_bikeshare_q1_2012 
WHERE start_time < '2012-01-08' 
WINDOW ntile_window AS 
	(PARTITION BY start_terminal ORDER BY duration_seconds) 
ORDER BY start_terminal, duration_seconds

SELECT * 
FROM benn.college_football_players

SELECT * 
FROM benn.college_football_teams

-- This alone gives one row for each year for each conference (e.g. there are four total ACC rows; one for freshmen, one for sophs, etc.)
SELECT teams.conference AS conference,
       players.year AS year,
       COUNT(1) AS players
  FROM benn.college_football_players players
  JOIN benn.college_football_teams teams
    ON teams.school_name = players.school_name
 GROUP BY conference, year
 ORDER BY conference, year 
 
-- But our goal is to get it so that there’s only one row for each conference, where each row has columns designated to freshmen, sophomores, etc.
-- To get there, put that original query into a subquery, and then act on that subquery using other functions (SUM, in this case)
SELECT conference, 
SUM(CASE WHEN year = 'FR' THEN players ELSE NULL END) AS fr_players, 
SUM(CASE WHEN year = 'SO' THEN players ELSE NULL END) AS so_players, 
SUM(CASE WHEN year = 'JR' THEN players ELSE NULL END) AS jr_players, 
SUM(CASE WHEN year = 'SR' THEN players ELSE NULL END) AS sr_players 
FROM ( 
	SELECT teams.conference AS conference, players.year AS year, COUNT(1) AS players 
	FROM benn.college_football_players players 
	JOIN benn.college_football_teams teams 
	ON teams.school_name = players.school_name 
	GROUP BY conference, year 
	) sub 
GROUP BY conference 
ORDER BY conference

-- That’s already pretty good, but for what it’s worth, we could adjust it so that we add a “total players” column across the four years
-- Then order the outer query by the number of total players instead of ordering by conference, as such:
SELECT conference, 
SUM(players) AS total_players,
SUM(CASE WHEN year = 'FR' THEN players ELSE NULL END) AS fr_players, 
SUM(CASE WHEN year = 'SO' THEN players ELSE NULL END) AS so_players, 
SUM(CASE WHEN year = 'JR' THEN players ELSE NULL END) AS jr_players, 
SUM(CASE WHEN year = 'SR' THEN players ELSE NULL END) AS sr_players 
FROM ( 
	SELECT teams.conference AS conference, players.year AS year, COUNT(1) AS players 
	FROM benn.college_football_players players 
	JOIN benn.college_football_teams teams 
	ON teams.school_name = players.school_name 
	GROUP BY conference, year 
	) sub 
GROUP BY conference 
ORDER BY total_players DESC

SELECT *
  FROM tutorial.worldwide_earthquakes
  
  SELECT year
  FROM (VALUES (2000),(2001),(2002),(2003),(2004),(2005),(2006),
               (2007),(2008),(2009),(2010),(2011),(2012)) v(year)
               
-- The reason the above query is useful is because we can now CROSS JOIN that with the worldwide_earthquakes table to create an expanded view:
SELECT years.*, earthquakes.* 
FROM tutorial.worldwide_earthquakes earthquakes 
CROSS JOIN ( 
	SELECT year 
	FROM (VALUES (2000),(2001),(2002),(2003),(2004),(2005),(2006), (2007),(2008),(2009),(2010),(2011),(2012)) v(year) 
	) years
	
-- But that query on its own still replicates each row 13 times
-- To fix this, we have to use a CASE statement that pulls data from the correct column in the earthquakes table, given the value in the year column at that given moment:
SELECT years.*, earthquakes.magnitude, 
CASE year 
	WHEN 2000 THEN year_2000 
	WHEN 2001 THEN year_2001 
	WHEN 2002 THEN year_2002 
	WHEN 2003 THEN year_2003 
	WHEN 2004 THEN year_2004 
	WHEN 2005 THEN year_2005 
	WHEN 2006 THEN year_2006 
	WHEN 2007 THEN year_2007 
	WHEN 2008 THEN year_2008 
	WHEN 2009 THEN year_2009 
	WHEN 2010 THEN year_2010 
	WHEN 2011 THEN year_2011 
	WHEN 2012 THEN year_2012 
	ELSE NULL END 
	AS number_of_earthquakes 
FROM tutorial.worldwide_earthquakes earthquakes 
CROSS JOIN ( 
	SELECT year 
	FROM (VALUES (2000),(2001),(2002),(2003),(2004),(2005),(2006), (2007),(2008),(2009),(2010),(2011),(2012)) v(year)
	 ) years
